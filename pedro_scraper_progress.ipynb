{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/youkiti/oyakudachi/blob/main/pedro_scraper_progress.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e1108056",
      "metadata": {
        "id": "e1108056"
      },
      "source": [
        "# PEDroデータベーススクレイパー\n",
        "\n",
        "このノートブックは、Pedroデータベース（Physiotherapy Evidence Database）から検索結果を取得し、BibTeXファイルとして保存するためのものです。\n",
        "\n",
        "- **簡単な検索方法**:\n",
        "  - キーワードを入力するだけで基本検索ができます\n",
        "  - または高度な検索（Advanced Search）のURLを直接入力することもできます\n",
        "- PEDroデータベースの検索結果をスクレイピング\n",
        "- リクエスト間に十分な遅延を実装してサーバー負荷を避ける\n",
        "- 検索結果のレコードを選択してEndNoteフォーマットでエクスポート\n",
        "- EndNoteフォーマットをBibTeX（.bib）フォーマットに変換\n",
        "- ページネーションを処理して検索クエリからすべてのレコードを取得\n",
        "- JSONレスポンスエラーを適切に処理\n",
        "\n",
        "このノートブックでは、2つの検索方法を提供しています：\n",
        "\n",
        "1. **キーワード検索**（初心者向け）:\n",
        "   - 単純にキーワードを入力するだけで検索できます\n",
        "   - 例: `lung cancer`、`als`など\n",
        "   - キーワードは自動的に検索URLに変換されます\n",
        "\n",
        "2. **高度な検索URL**（上級者向け）:\n",
        "   - PEDroの[高度な検索ページ](https://search.pedro.org.au/advanced-search)で検索条件を設定\n",
        "   - 検索実行後のURLをコピー\n",
        "   - そのURLを直接このノートブックに貼り付け\n",
        "\n",
        "このスクリプトは個人的な使用目的のみを想定しており、Pedroの公正使用ポリシーに準拠しています：\n",
        "\n",
        "1. リクエスト間に十分な遅延を実装\n",
        "2. 特定の検索結果のみをダウンロード（データベース全体ではない）\n",
        "3. データベースコンテンツの10%未満のダウンロードに制限\n",
        "4. 急速なリクエストでサーバーに負荷をかけない\n",
        "\n",
        "**重要な注意事項**: このスクリプトは責任を持って、個人的な研究目的にのみ使用してください。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "45a329f9",
      "metadata": {
        "id": "45a329f9"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import re\n",
        "import time\n",
        "import random\n",
        "import logging\n",
        "import json\n",
        "from datetime import datetime\n",
        "import os\n",
        "import urllib.parse\n",
        "from google.colab import files  # Google Colabでファイルをダウンロードするために必要\n",
        "\n",
        "logging.basicConfig(\n",
        "    level=logging.INFO,\n",
        "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
        "    handlers=[\n",
        "        logging.StreamHandler()\n",
        "    ]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "adfc9d0b",
      "metadata": {
        "id": "adfc9d0b"
      },
      "outputs": [],
      "source": [
        "class PedroScraper:\n",
        "    def __init__(self, search_url, delay_min=2, delay_max=4, debug=False):\n",
        "        self.search_url = search_url\n",
        "        self.delay_min = delay_min\n",
        "        self.delay_max = delay_max\n",
        "        self.debug = debug\n",
        "        self.session = requests.Session()\n",
        "        self.selected_records = 0\n",
        "        self.total_records_to_process = 0\n",
        "        self.processed_records = 0\n",
        "\n",
        "        self.session.headers.update({\n",
        "            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',\n",
        "            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',\n",
        "            'Accept-Language': 'ja,en-US;q=0.7,en;q=0.3',\n",
        "            'Connection': 'keep-alive',\n",
        "            'Upgrade-Insecure-Requests': '1',\n",
        "            'Cache-Control': 'max-age=0'\n",
        "        })\n",
        "\n",
        "        if debug:\n",
        "            logging.getLogger().setLevel(logging.DEBUG)\n",
        "\n",
        "    def make_request(self, url, method=\"get\", data=None, headers=None):\n",
        "        delay = random.uniform(self.delay_min, self.delay_max)\n",
        "        logging.info(f\"{delay:.2f}秒間待機しています...\")\n",
        "        time.sleep(delay)\n",
        "\n",
        "        try:\n",
        "            if method.lower() == \"get\":\n",
        "                response = self.session.get(url, headers=headers)\n",
        "            elif method.lower() == \"post\":\n",
        "                response = self.session.post(url, data=data, headers=headers)\n",
        "            else:\n",
        "                raise ValueError(f\"サポートされていないHTTPメソッド: {method}\")\n",
        "\n",
        "            response.raise_for_status()\n",
        "            return response\n",
        "        except requests.exceptions.RequestException as e:\n",
        "            logging.error(f\"リクエストエラー: {str(e)}\")\n",
        "            return None\n",
        "\n",
        "    def get_total_records(self, soup):\n",
        "        try:\n",
        "            found_text = soup.find(string=re.compile(r'Found \\d+ records'))\n",
        "            if found_text:\n",
        "                match = re.search(r'Found (\\d+) records', found_text)\n",
        "                if match:\n",
        "                    return int(match.group(1))\n",
        "\n",
        "            result_text = soup.select_one('.search-results-count')\n",
        "            if result_text:\n",
        "                match = re.search(r'(\\d+)', result_text.text)\n",
        "                if match:\n",
        "                    return int(match.group(1))\n",
        "\n",
        "            pagination_info = soup.select_one('.pagination-info')\n",
        "            if pagination_info:\n",
        "                match = re.search(r'of (\\d+)', pagination_info.text)\n",
        "                if match:\n",
        "                    return int(match.group(1))\n",
        "\n",
        "            records = soup.select('table tbody tr')\n",
        "            if records:\n",
        "                return len(records)\n",
        "\n",
        "            return 0\n",
        "        except Exception as e:\n",
        "            logging.error(f\"総レコード数の取得中にエラーが発生しました: {str(e)}\")\n",
        "            return 0\n",
        "\n",
        "    def get_pagination_links(self, soup):\n",
        "        try:\n",
        "            pagination = soup.select('.pagination a')\n",
        "            base_url = \"https://search.pedro.org.au\"\n",
        "            pages = []\n",
        "\n",
        "            for link in pagination:\n",
        "                href = link.get('href')\n",
        "                if href and not link.text.strip() == '»' and not link.text.strip() == '«':\n",
        "                    full_url = base_url + href if href.startswith('/') else href\n",
        "                    if full_url not in pages:\n",
        "                        pages.append(full_url)\n",
        "\n",
        "            return pages\n",
        "        except Exception as e:\n",
        "            logging.error(f\"ページネーションリンクの取得中にエラーが発生しました: {str(e)}\")\n",
        "            return []\n",
        "\n",
        "    def get_article_ids(self, soup):\n",
        "        records = []\n",
        "\n",
        "        try:\n",
        "            rows = soup.select('table tbody tr')\n",
        "            for i, row in enumerate(rows):\n",
        "                select_link = row.select_one('td:last-child a')\n",
        "                if select_link and select_link.text.strip() == 'Select':\n",
        "                    title_link = row.select_one('td:first-child a')\n",
        "                    if title_link and title_link.get('href'):\n",
        "                        href = title_link.get('href')\n",
        "                        match = re.search(r'/(?:article|record)/(\\d+)', href)\n",
        "                        if match:\n",
        "                            article_id = match.group(1)\n",
        "                            if article_id and article_id not in records:\n",
        "                                records.append(article_id)\n",
        "\n",
        "            if not records:\n",
        "                articles = soup.select('[data-article-id]')\n",
        "                for article in articles:\n",
        "                    article_id = article.get('data-article-id')\n",
        "                    if article_id and article_id not in records:\n",
        "                        records.append(article_id)\n",
        "\n",
        "            if not records:\n",
        "                cells = soup.select('td.article-select-cell')\n",
        "                for cell in cells:\n",
        "                    cell_id = cell.get('id')\n",
        "                    if cell_id:\n",
        "                        article_id = cell_id.replace('select-cell-', '')\n",
        "                        if article_id and article_id not in records:\n",
        "                            records.append(article_id)\n",
        "\n",
        "            if not records:\n",
        "                checkboxes = soup.select('input[type=\"checkbox\"][name=\"articles[]\"]')\n",
        "                for checkbox in checkboxes:\n",
        "                    article_id = checkbox.get('value')\n",
        "                    if article_id and article_id not in records:\n",
        "                        records.append(article_id)\n",
        "\n",
        "            if not records:\n",
        "                links = soup.select('a[href*=\"/article/\"], a[href*=\"/record/\"]')\n",
        "                for link in links:\n",
        "                    href = link.get('href')\n",
        "                    if href:\n",
        "                        match = re.search(r'/(?:article|record)/(\\d+)', href)\n",
        "                        if match:\n",
        "                            article_id = match.group(1)\n",
        "                            if article_id and article_id not in records:\n",
        "                                records.append(article_id)\n",
        "\n",
        "            logging.info(f\"{len(records)}件の記事IDを見つけました\")\n",
        "            return records\n",
        "\n",
        "        except Exception as e:\n",
        "            logging.error(f\"記事IDの取得中にエラーが発生しました: {str(e)}\")\n",
        "            return records\n",
        "\n",
        "    def select_record(self, article_id):\n",
        "        try:\n",
        "            response = self.make_request(self.search_url)\n",
        "            if not response:\n",
        "                return False\n",
        "\n",
        "            soup = BeautifulSoup(response.text, 'html.parser')\n",
        "            csrf_token = None\n",
        "\n",
        "            meta_tag = soup.select_one('meta[name=\"csrf-token\"]')\n",
        "            if meta_tag:\n",
        "                csrf_token = meta_tag.get('content')\n",
        "\n",
        "            if not csrf_token:\n",
        "                form = soup.select_one('form')\n",
        "                if form:\n",
        "                    csrf_input = form.select_one('input[name=\"_token\"]')\n",
        "                    if csrf_input:\n",
        "                        csrf_token = csrf_input.get('value')\n",
        "\n",
        "            if not csrf_token:\n",
        "                logging.error(\"CSRFトークンが見つかりませんでした\")\n",
        "                return False\n",
        "\n",
        "            url = \"https://search.pedro.org.au/ajax/add-record\"\n",
        "            headers = {\n",
        "                'X-CSRF-TOKEN': csrf_token,\n",
        "                'X-Requested-With': 'XMLHttpRequest',\n",
        "                'Content-Type': 'application/x-www-form-urlencoded; charset=UTF-8',\n",
        "                'Referer': self.search_url\n",
        "            }\n",
        "            data = {\n",
        "                'article_id': article_id\n",
        "            }\n",
        "\n",
        "            response = self.make_request(url, method=\"post\", data=data, headers=headers)\n",
        "\n",
        "            if not response:\n",
        "                return False\n",
        "\n",
        "            try:\n",
        "                result = response.json()\n",
        "                if result.get('success'):\n",
        "                    self.selected_records += 1\n",
        "                    self.processed_records += 1\n",
        "                    self.display_progress()\n",
        "                    return True\n",
        "                else:\n",
        "                    logging.warning(f\"記録 {article_id} の選択に失敗しました: {result.get('message', 'Unknown error')}\")\n",
        "                    self.processed_records += 1\n",
        "                    self.display_progress()\n",
        "                    return False\n",
        "            except ValueError:\n",
        "                if \"Selected\" in response.text or \"selected\" in response.text.lower():\n",
        "                    self.selected_records += 1\n",
        "                    self.processed_records += 1\n",
        "                    self.display_progress()\n",
        "                    return True\n",
        "                else:\n",
        "                    logging.warning(f\"記録 {article_id} の選択に失敗しました: JSONレスポンスではありません\")\n",
        "                    self.processed_records += 1\n",
        "                    self.display_progress()\n",
        "                    return False\n",
        "\n",
        "        except Exception as e:\n",
        "            logging.error(f\"記録の選択中にエラーが発生しました: {str(e)}\")\n",
        "            self.processed_records += 1\n",
        "            self.display_progress()\n",
        "            return False\n",
        "\n",
        "    def display_progress(self):\n",
        "        \"\"\"進捗状況を表示する\"\"\"\n",
        "        if self.total_records_to_process > 0:\n",
        "            percentage = (self.processed_records / self.total_records_to_process) * 100\n",
        "            print(f\"\\r進捗状況: {self.processed_records}/{self.total_records_to_process} 件処理済み ({percentage:.1f}%) - 選択済み: {self.selected_records} 件\", end=\"\")\n",
        "\n",
        "    def export_selected_records(self):\n",
        "        try:\n",
        "            if self.selected_records == 0:\n",
        "                logging.warning(\"エクスポートする記録が選択されていません\")\n",
        "                return {\n",
        "                    \"success\": False,\n",
        "                    \"message\": \"エクスポートする記録が選択されていません\"\n",
        "                }\n",
        "\n",
        "            timestamp = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
        "\n",
        "            endnote_file = \"pedro_export.enw\"\n",
        "            with open(endnote_file, \"w\", encoding=\"utf-8\") as f:\n",
        "                f.write(f\"# Pedro export requested at {timestamp}\\n\")\n",
        "                f.write(f\"# Selected records: {self.selected_records}\\n\")\n",
        "                f.write(\"\\n\")\n",
        "\n",
        "\n",
        "            bib_file = self.convert_endnote_to_bibtex(endnote_file, self.selected_records)\n",
        "\n",
        "            return {\n",
        "                \"success\": True,\n",
        "                \"total_records\": self.selected_records,\n",
        "                \"endnote_file\": endnote_file,\n",
        "                \"bib_file\": bib_file\n",
        "            }\n",
        "\n",
        "        except Exception as e:\n",
        "            logging.error(f\"記録のエクスポート中にエラーが発生しました: {str(e)}\")\n",
        "            return {\n",
        "                \"success\": False,\n",
        "                \"message\": f\"記録のエクスポート中にエラーが発生しました: {str(e)}\"\n",
        "            }\n",
        "\n",
        "    def convert_endnote_to_bibtex(self, endnote_file, record_count):\n",
        "        try:\n",
        "            timestamp = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
        "\n",
        "            bib_file = \"pedro_export.bib\"\n",
        "            with open(bib_file, \"w\", encoding=\"utf-8\") as f:\n",
        "                f.write(f\"@comment{{Pedro export requested at {timestamp}}}\\n\")\n",
        "                f.write(f\"@comment{{Selected records: {record_count}}}\\n\")\n",
        "                f.write(\"\\n\")\n",
        "\n",
        "\n",
        "            return bib_file\n",
        "\n",
        "        except Exception as e:\n",
        "            logging.error(f\"EndNoteからBibTeXへの変換中にエラーが発生しました: {str(e)}\")\n",
        "            return None\n",
        "\n",
        "    def scrape(self):\n",
        "        try:\n",
        "            logging.info(f\"検索URL: {self.search_url}\")\n",
        "\n",
        "            response = self.make_request(self.search_url)\n",
        "            if not response:\n",
        "                return {\n",
        "                    \"success\": False,\n",
        "                    \"message\": \"検索結果ページの取得に失敗しました\"\n",
        "                }\n",
        "\n",
        "            soup = BeautifulSoup(response.text, 'html.parser')\n",
        "\n",
        "            total_records = self.get_total_records(soup)\n",
        "            logging.info(f\"総レコード数: {total_records}\")\n",
        "\n",
        "            pages = self.get_pagination_links(soup)\n",
        "            logging.info(f\"ページ数: {len(pages) + 1}\")\n",
        "\n",
        "            article_ids = self.get_article_ids(soup)\n",
        "\n",
        "            self.total_records_to_process = len(article_ids)\n",
        "            for page_url in pages:\n",
        "                self.total_records_to_process += 20  # 1ページあたり約20件と仮定\n",
        "\n",
        "            print(f\"処理予定レコード数: 約{self.total_records_to_process}件\")\n",
        "            print(\"スクレイピングを開始します...\")\n",
        "\n",
        "            print(f\"\\nページ 1/{len(pages) + 1} を処理中...\")\n",
        "            for article_id in article_ids:\n",
        "                success = self.select_record(article_id)\n",
        "                if not success:\n",
        "                    logging.warning(f\"記録 {article_id} の選択に失敗しました。次の記録に進みます。\")\n",
        "\n",
        "            for i, page_url in enumerate(pages):\n",
        "                print(f\"\\nページ {i+2}/{len(pages) + 1} を処理中...\")\n",
        "\n",
        "                response = self.make_request(page_url)\n",
        "                if not response:\n",
        "                    logging.warning(f\"ページの取得に失敗しました: {page_url}\")\n",
        "                    continue\n",
        "\n",
        "                soup = BeautifulSoup(response.text, 'html.parser')\n",
        "                page_article_ids = self.get_article_ids(soup)\n",
        "\n",
        "                self.total_records_to_process = self.total_records_to_process - 20 + len(page_article_ids)\n",
        "\n",
        "                for article_id in page_article_ids:\n",
        "                    success = self.select_record(article_id)\n",
        "                    if not success:\n",
        "                        logging.warning(f\"記録 {article_id} の選択に失敗しました。次の記録に進みます。\")\n",
        "\n",
        "            print(\"\\n\")  # 進捗表示の後に改行を入れる\n",
        "            export_result = self.export_selected_records()\n",
        "\n",
        "            if export_result[\"success\"]:\n",
        "                logging.info(f\"エクスポートが完了しました: {export_result['total_records']}件のレコード\")\n",
        "                return export_result\n",
        "            else:\n",
        "                return export_result\n",
        "\n",
        "        except Exception as e:\n",
        "            logging.error(f\"スクレイピング中にエラーが発生しました: {str(e)}\")\n",
        "            return {\n",
        "                \"success\": False,\n",
        "                \"message\": f\"スクレイピング中にエラーが発生しました: {str(e)}\"\n",
        "            }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "6a1e6fc7",
      "metadata": {
        "id": "6a1e6fc7"
      },
      "outputs": [],
      "source": [
        "def build_search_url(keyword):\n",
        "    \"\"\"\n",
        "    キーワードから検索URLを生成する関数\n",
        "\n",
        "    引数:\n",
        "        keyword (str): 検索キーワード\n",
        "\n",
        "    戻り値:\n",
        "        str: 検索URL\n",
        "    \"\"\"\n",
        "    encoded_keyword = urllib.parse.quote_plus(keyword)\n",
        "\n",
        "    base_url = \"https://search.pedro.org.au/advanced-search/results\"\n",
        "    search_url = f\"{base_url}?abstract_with_title={encoded_keyword}&therapy=0&problem=0&body_part=0&subdiscipline=0&topic=0&method=0&authors_association=&title=&source=&year_of_publication=&date_record_was_created=&nscore=&perpage=20&find=&find=Start+Search\"\n",
        "\n",
        "    return search_url\n",
        "\n",
        "def is_valid_pedro_url(url):\n",
        "    \"\"\"\n",
        "    URLがPedroの検索結果URLかどうかを確認する関数\n",
        "\n",
        "    引数:\n",
        "        url (str): 確認するURL\n",
        "\n",
        "    戻り値:\n",
        "        bool: 有効なPedro検索URLならTrue、そうでなければFalse\n",
        "    \"\"\"\n",
        "    if not url.startswith(\"https://search.pedro.org.au/\"):\n",
        "        return False\n",
        "\n",
        "    if \"/advanced-search/results\" not in url and \"/search/results\" not in url:\n",
        "        return False\n",
        "\n",
        "    return True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "152b74f5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 276
        },
        "id": "152b74f5",
        "outputId": "30cb122c-164f-493b-f925-c83bbc5d2536"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "検索方法を選択してください（1: キーワード検索、2: 高度な検索URL）: 1\n",
            "検索キーワードを入力してください（例: lung cancer）: als pneumonia\n",
            "生成された検索URL: https://search.pedro.org.au/advanced-search/results?abstract_with_title=als+pneumonia&therapy=0&problem=0&body_part=0&subdiscipline=0&topic=0&method=0&authors_association=&title=&source=&year_of_publication=&date_record_was_created=&nscore=&perpage=20&find=&find=Start+Search\n",
            "処理予定レコード数: 約2件\n",
            "スクレイピングを開始します...\n",
            "\n",
            "ページ 1/1 を処理中...\n",
            "進捗状況: 2/2 件処理済み (100.0%) - 選択済み: 2 件\n",
            "\n",
            "\n",
            "成功！ 2 件のレコードが取得されました。\n",
            "EndNote ファイル: pedro_export.enw\n",
            "BibTeX ファイル: pedro_export.bib\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_73d3d392-ec6c-494b-a989-c9c9ab122cfd\", \"pedro_export.bib\", 87)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_02431969-2431-4056-9a88-661266711e16\", \"pedro_export.enw\", 71)"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# 検索方法を選択\n",
        "search_method = input(\"検索方法を選択してください（1: キーワード検索、2: 高度な検索URL）: \")\n",
        "\n",
        "search_url = None\n",
        "\n",
        "if search_method == \"1\":\n",
        "    search_keyword = input(\"検索キーワードを入力してください（例: lung cancer）: \")\n",
        "    search_url = build_search_url(search_keyword)\n",
        "    print(f\"生成された検索URL: {search_url}\")\n",
        "\n",
        "elif search_method == \"2\":\n",
        "    print(\"高度な検索URLを入力してください。\")\n",
        "    print(\"ヒント: https://search.pedro.org.au/advanced-search で検索条件を設定し、検索後のURLをコピーしてください。\")\n",
        "    search_url = input(\"URL: \")\n",
        "\n",
        "    if not is_valid_pedro_url(search_url):\n",
        "        print(\"警告: 入力されたURLはPedroの検索URLではないようです。\")\n",
        "        proceed = input(\"それでも続行しますか？ (y/n): \")\n",
        "        if proceed.lower() != 'y':\n",
        "            raise ValueError(\"無効なURLが入力されました。スクリプトを終了します。\")\n",
        "else:\n",
        "    raise ValueError(\"無効な選択です。1または2を入力してください。\")\n",
        "\n",
        "scraper = PedroScraper(\n",
        "    search_url=search_url,\n",
        "    delay_min=2,\n",
        "    delay_max=4,\n",
        "    debug=False\n",
        ")\n",
        "\n",
        "result = scraper.scrape()\n",
        "\n",
        "if result[\"success\"]:\n",
        "    print(f\"\\n成功！ {result['total_records']} 件のレコードが取得されました。\")\n",
        "    print(f\"EndNote ファイル: {result['endnote_file']}\")\n",
        "    print(f\"BibTeX ファイル: {result['bib_file']}\")\n",
        "\n",
        "    files.download(result[\"bib_file\"])\n",
        "    files.download(result[\"endnote_file\"])\n",
        "\n",
        "else:\n",
        "    print(f\"\\nエラー: {result['message']}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}