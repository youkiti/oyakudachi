{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/youkiti/oyakudachi/blob/main/pedro_scraper_progress.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e1108056",
      "metadata": {
        "id": "e1108056"
      },
      "source": [
        "# PEDroデータベーススクレイパー\n",
        "\n",
        "このノートブックは、Pedroデータベース（Physiotherapy Evidence Database）から検索結果を取得し、BibTeXファイルとして保存するためのものです。\n",
        "\n",
        "- **簡単な検索方法**:\n",
        "  - キーワードを入力するだけで基本検索ができます\n",
        "  - または高度な検索（Advanced Search）のURLを直接入力することもできます\n",
        "- PEDroデータベースの検索結果をスクレイピング\n",
        "- リクエスト間に十分な遅延を実装してサーバー負荷を避ける\n",
        "- 検索結果のレコードを選択してEndNoteフォーマットでエクスポート\n",
        "- EndNoteフォーマットをBibTeX（.bib）フォーマットに変換\n",
        "- ページネーションを処理して検索クエリからすべてのレコードを取得\n",
        "- JSONレスポンスエラーを適切に処理\n",
        "\n",
        "このノートブックでは、2つの検索方法を提供しています：\n",
        "\n",
        "1. **キーワード検索**（初心者向け）:\n",
        "   - 単純にキーワードを入力するだけで検索できます\n",
        "   - 例: `lung cancer`、`als`など\n",
        "   - キーワードは自動的に検索URLに変換されます\n",
        "\n",
        "2. **高度な検索URL**（上級者向け）:\n",
        "   - PEDroの[高度な検索ページ](https://search.pedro.org.au/advanced-search)で検索条件を設定\n",
        "   - 検索実行後のURLをコピー\n",
        "   - そのURLを直接このノートブックに貼り付け\n",
        "\n",
        "このスクリプトは個人的な使用目的のみを想定しており、Pedroの公正使用ポリシーに準拠しています：\n",
        "\n",
        "1. リクエスト間に十分な遅延を実装\n",
        "2. 特定の検索結果のみをダウンロード（データベース全体ではない）\n",
        "3. データベースコンテンツの10%未満のダウンロードに制限\n",
        "4. 急速なリクエストでサーバーに負荷をかけない\n",
        "\n",
        "**重要な注意事項**: このスクリプトは責任を持って、個人的な研究目的にのみ使用してください。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "45a329f9",
      "metadata": {
        "id": "45a329f9"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import re\n",
        "import time\n",
        "import random\n",
        "import logging\n",
        "import json\n",
        "from datetime import datetime\n",
        "import os\n",
        "import urllib.parse\n",
        "from google.colab import files  # Google Colabでファイルをダウンロードするために必要\n",
        "\n",
        "logging.basicConfig(\n",
        "    level=logging.INFO,\n",
        "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
        "    handlers=[\n",
        "        logging.StreamHandler()\n",
        "    ]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "adfc9d0b",
      "metadata": {
        "id": "adfc9d0b"
      },
      "outputs": [],
      "source": [
        "class PedroScraper:\n",
        "    \"\"\"Pedroデータベースから検索結果を取得し、BibTeXファイルとして保存するクラス\"\"\"\n",
        "\n",
        "    def __init__(self, search_url, delay_min=2, delay_max=4, debug=False):\n",
        "        \"\"\"初期化\"\"\"\n",
        "        self.search_url = search_url\n",
        "        self.delay_min = delay_min\n",
        "        self.delay_max = delay_max\n",
        "        self.debug = debug\n",
        "        self.selected_records = []\n",
        "        self.total_records = 0\n",
        "        self.base_url = \"https://search.pedro.org.au\"\n",
        "\n",
        "        if self.debug:\n",
        "            logging.getLogger().setLevel(logging.DEBUG)\n",
        "\n",
        "    def make_request(self, url):\n",
        "        \"\"\"指定されたURLにリクエストを送信する\"\"\"\n",
        "        try:\n",
        "            headers = {\n",
        "                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'\n",
        "            }\n",
        "            response = requests.get(url, headers=headers, timeout=30)\n",
        "\n",
        "            if response.status_code == 200:\n",
        "                return response\n",
        "            else:\n",
        "                logging.error(f\"リクエスト失敗: ステータスコード {response.status_code}\")\n",
        "                return None\n",
        "        except Exception as e:\n",
        "            logging.error(f\"リクエスト中にエラーが発生しました: {str(e)}\")\n",
        "            return None\n",
        "\n",
        "    def get_total_records(self, soup):\n",
        "        \"\"\"検索結果の総レコード数を取得する\"\"\"\n",
        "        try:\n",
        "            result_text = soup.find(string=lambda s: s and \"Found\" in s and \"records\" in s)\n",
        "            if result_text:\n",
        "                match = re.search(r'Found\\s+(\\d+)\\s+records', result_text)\n",
        "                if match:\n",
        "                    return int(match.group(1))\n",
        "\n",
        "            result_count_elem = soup.select_one('.result-count')\n",
        "            if result_count_elem:\n",
        "                match = re.search(r'(\\d+)', result_count_elem.text)\n",
        "                if match:\n",
        "                    return int(match.group(1))\n",
        "\n",
        "            table = soup.select_one('table.search-results')\n",
        "            if not table:\n",
        "                table = soup.select_one('table.browse_records')\n",
        "            if not table:\n",
        "                table = soup.select_one('table')\n",
        "\n",
        "            if table:\n",
        "                rows = table.select('tbody tr')\n",
        "                if len(rows) > 0:\n",
        "                    return len(rows)\n",
        "\n",
        "            return 0\n",
        "        except Exception as e:\n",
        "            logging.error(f\"総レコード数の取得中にエラーが発生しました: {str(e)}\")\n",
        "            return 0\n",
        "\n",
        "    def get_pagination_links(self, soup):\n",
        "        \"\"\"ページネーションリンクを取得する\"\"\"\n",
        "        pagination_links = []\n",
        "        try:\n",
        "            pagination = soup.select('.pagination a')\n",
        "            for link in pagination:\n",
        "                href = link.get('href')\n",
        "                if href and 'page=' in href:\n",
        "                    full_url = urllib.parse.urljoin(self.base_url, href)\n",
        "                    pagination_links.append(full_url)\n",
        "        except Exception as e:\n",
        "            logging.error(f\"ページネーションリンクの取得中にエラーが発生しました: {str(e)}\")\n",
        "\n",
        "        return pagination_links\n",
        "\n",
        "    def extract_table_records(self, soup):\n",
        "        \"\"\"検索結果テーブルからレコード情報を抽出する\"\"\"\n",
        "        records = []\n",
        "\n",
        "        try:\n",
        "            table = soup.select_one('table.search-results')\n",
        "            if not table:\n",
        "                table = soup.select_one('table.browse_records')\n",
        "            if not table:\n",
        "                table = soup.select_one('table')\n",
        "\n",
        "            if not table:\n",
        "                logging.error(\"検索結果テーブルが見つかりませんでした\")\n",
        "                return records\n",
        "\n",
        "            rows = table.select('tr')\n",
        "\n",
        "            for row in rows[1:]:\n",
        "                try:\n",
        "                    columns = row.select('td')\n",
        "\n",
        "                    if len(columns) >= 4:  # タイトル、メソッド、スコア、選択ボタンの列があることを確認\n",
        "                        title_col = columns[0]\n",
        "                        title_link = title_col.select_one('a')\n",
        "\n",
        "                        if title_link:\n",
        "                            title = title_link.text.strip()\n",
        "                            link = title_link.get('href')\n",
        "                            if link:\n",
        "                                full_link = urllib.parse.urljoin(self.base_url, link)\n",
        "                                record_id = link.split('/')[-1] if '/' in link else None\n",
        "                            else:\n",
        "                                full_link = None\n",
        "                                record_id = None\n",
        "                        else:\n",
        "                            title = title_col.text.strip()\n",
        "                            full_link = None\n",
        "                            record_id = None\n",
        "\n",
        "                        method = columns[1].text.strip() if len(columns) > 1 else \"N/A\"\n",
        "\n",
        "                        score = columns[2].text.strip() if len(columns) > 2 else \"N/A\"\n",
        "\n",
        "                        if record_id and title:\n",
        "                            records.append({\n",
        "                                'id': record_id,\n",
        "                                'title': title,\n",
        "                                'method': method,\n",
        "                                'score': score,\n",
        "                                'url': full_link\n",
        "                            })\n",
        "                            logging.debug(f\"レコード抽出: ID={record_id}, タイトル={title}, メソッド={method}, スコア={score}\")\n",
        "                except Exception as e:\n",
        "                    logging.error(f\"行の処理中にエラーが発生しました: {str(e)}\")\n",
        "                    continue\n",
        "\n",
        "        except Exception as e:\n",
        "            logging.error(f\"テーブルレコードの抽出中にエラーが発生しました: {str(e)}\")\n",
        "\n",
        "        return records\n",
        "\n",
        "    def get_record_details(self, record_id, url):\n",
        "        \"\"\"記録の詳細情報を抽出する\"\"\"\n",
        "        response = self.make_request(url)\n",
        "        if not response:\n",
        "            logging.error(f\"記録 {record_id} の詳細情報の取得に失敗しました\")\n",
        "            return None\n",
        "\n",
        "        if self.debug:\n",
        "            with open(f\"debug_detail_{record_id}.html\", \"w\", encoding=\"utf-8\") as f:\n",
        "                f.write(response.text)\n",
        "            logging.debug(f\"詳細ページのHTMLを保存しました: debug_detail_{record_id}.html\")\n",
        "\n",
        "        soup = BeautifulSoup(response.text, 'html.parser')\n",
        "\n",
        "        try:\n",
        "            tables = soup.find_all('table', class_='browse_records')\n",
        "            if not tables:\n",
        "                tables = soup.select('#search-content table')\n",
        "\n",
        "            title = \"\"\n",
        "            if tables:\n",
        "                for table in tables:\n",
        "                    strong_elems = table.select('tr:nth-child(1) td strong')\n",
        "                    if not strong_elems:\n",
        "                        strong_elems = table.find_all('strong')\n",
        "\n",
        "                    if strong_elems and len(strong_elems) > 0:\n",
        "                        title = strong_elems[0].text.strip()\n",
        "                        logging.debug(f\"テーブル内の強調テキストからタイトルを取得: {title}\")\n",
        "                        break\n",
        "\n",
        "            if not title:\n",
        "                h1_elem = soup.select_one('h1.article-title')\n",
        "                if not h1_elem:\n",
        "                    h1_elem = soup.select_one('h1')\n",
        "                if h1_elem:\n",
        "                    title = h1_elem.text.strip()\n",
        "                    logging.debug(f\"h1要素からタイトルを取得: {title}\")\n",
        "\n",
        "            authors = \"\"\n",
        "            if tables:\n",
        "                for table in tables:\n",
        "                    author_elems = table.select('tr:nth-child(2) td')\n",
        "                    if author_elems and len(author_elems) > 0:\n",
        "                        authors = author_elems[0].text.strip()\n",
        "                        logging.debug(f\"テーブル内の2番目の行から著者情報を取得: {authors}\")\n",
        "                        break\n",
        "\n",
        "            source = \"\"\n",
        "            if tables:\n",
        "                for table in tables:\n",
        "                    journal_elems = table.select('tr:nth-child(3) td')\n",
        "                    if journal_elems and len(journal_elems) > 0:\n",
        "                        source = journal_elems[0].text.strip()\n",
        "                        logging.debug(f\"テーブル内の3番目の行からジャーナル情報を取得: {source}\")\n",
        "                        break\n",
        "\n",
        "            abstract = \"This record does not have an abstract.\"\n",
        "\n",
        "            if tables:\n",
        "                for table in tables:\n",
        "                    abstract_elems = table.select('tr:nth-child(5) td p')\n",
        "                    if abstract_elems and len(abstract_elems) > 0:\n",
        "                        abstract_text = abstract_elems[0].text.strip()\n",
        "                        if \"Full text\" in abstract_text:\n",
        "                            abstract_text = abstract_text.split(\"Full text\")[0].strip()\n",
        "                        abstract = abstract_text\n",
        "                        logging.debug(f\"テーブル内の5番目の行から抄録を取得\")\n",
        "                        break\n",
        "\n",
        "            year = \"\"\n",
        "            if source:\n",
        "                year_match = re.search(r'\\b(19|20)\\d{2}\\b', source)\n",
        "                if year_match:\n",
        "                    year = year_match.group(0)\n",
        "\n",
        "            return {\n",
        "                'id': record_id,\n",
        "                'title': title,\n",
        "                'authors': authors,\n",
        "                'year': year,\n",
        "                'source': source,\n",
        "                'abstract': abstract,\n",
        "                'url': url\n",
        "            }\n",
        "\n",
        "        except Exception as e:\n",
        "            logging.error(f\"記録 {record_id} の詳細情報の抽出中にエラーが発生しました: {str(e)}\")\n",
        "            return None\n",
        "\n",
        "    def select_record(self, record, table_record=None):\n",
        "        \"\"\"記録を選択して保存する\"\"\"\n",
        "        try:\n",
        "            if not record:\n",
        "                return False\n",
        "\n",
        "            if table_record:\n",
        "                record['method'] = table_record.get('method', 'N/A')\n",
        "                record['score'] = table_record.get('score', 'N/A')\n",
        "                if not record.get('title') and table_record.get('title'):\n",
        "                    record['title'] = table_record.get('title')\n",
        "\n",
        "            self.selected_records.append(record)\n",
        "            return True\n",
        "\n",
        "        except Exception as e:\n",
        "            logging.error(f\"記録の選択中にエラーが発生しました: {str(e)}\")\n",
        "            return False\n",
        "\n",
        "    def display_progress(self, current, total):\n",
        "        \"\"\"進捗状況を表示する\"\"\"\n",
        "        percentage = (current / total) * 100 if total > 0 else 0\n",
        "        print(f\"\\r進捗状況: {current}/{total} 件処理済み ({percentage:.1f}%) - 選択済み: {len(self.selected_records)} 件\", end=\"\")\n",
        "\n",
        "    def export_selected_records(self):\n",
        "        \"\"\"選択された記録をエクスポートする\"\"\"\n",
        "        if not self.selected_records:\n",
        "            logging.warning(\"エクスポートする記録がありません\")\n",
        "            return None\n",
        "\n",
        "        try:\n",
        "            now = datetime.now()\n",
        "            timestamp = now.strftime(\"%Y%m%d_%H%M%S\")\n",
        "\n",
        "            endnote_file = f\"pedro_export.enw\"\n",
        "            with open(endnote_file, \"w\", encoding=\"utf-8\") as f:\n",
        "                for record in self.selected_records:\n",
        "                    f.write(\"%0 Journal Article\\n\")\n",
        "\n",
        "                    if record.get('title'):\n",
        "                        f.write(f\"%T {record['title']}\\n\")\n",
        "\n",
        "                    if record.get('authors'):\n",
        "                        authors = record['authors'].split(',')\n",
        "                        for author in authors:\n",
        "                            author = author.strip()\n",
        "                            if author:\n",
        "                                f.write(f\"%A {author}\\n\")\n",
        "\n",
        "                    if record.get('year'):\n",
        "                        f.write(f\"%D {record['year']}\\n\")\n",
        "\n",
        "                    if record.get('source'):\n",
        "                        f.write(f\"%J {record['source']}\\n\")\n",
        "\n",
        "                    if record.get('abstract'):\n",
        "                        f.write(f\"%X {record['abstract']}\\n\")\n",
        "\n",
        "                    if record.get('url'):\n",
        "                        f.write(f\"%U {record['url']}\\n\")\n",
        "\n",
        "                    notes = []\n",
        "                    if record.get('method') and record['method'] != 'N/A':\n",
        "                        notes.append(f\"Method: {record['method']}\")\n",
        "                    if record.get('score') and record['score'] != 'N/A':\n",
        "                        notes.append(f\"Score: {record['score']}\")\n",
        "\n",
        "                    if notes:\n",
        "                        f.write(f\"%Z {'; '.join(notes)}\\n\")\n",
        "\n",
        "                    f.write(\"\\n\")\n",
        "\n",
        "            bibtex_file = self.convert_to_bibtex()\n",
        "\n",
        "            logging.info(f\"エクスポートが完了しました: {len(self.selected_records)}件のレコード\")\n",
        "\n",
        "            return {\n",
        "                \"endnote_file\": endnote_file,\n",
        "                \"bib_file\": bibtex_file\n",
        "            }\n",
        "\n",
        "        except Exception as e:\n",
        "            logging.error(f\"記録のエクスポート中にエラーが発生しました: {str(e)}\")\n",
        "            return None\n",
        "\n",
        "    def convert_to_bibtex(self):\n",
        "        \"\"\"選択された記録をBibTeX形式に変換する\"\"\"\n",
        "        if not self.selected_records:\n",
        "            return None\n",
        "\n",
        "        try:\n",
        "            bibtex_file = f\"pedro_export.bib\"\n",
        "            with open(bibtex_file, \"w\", encoding=\"utf-8\") as f:\n",
        "                for record in self.selected_records:\n",
        "                    first_author = \"\"\n",
        "                    if record.get('authors'):\n",
        "                        first_author_match = re.search(r'([A-Za-z\\-]+)', record['authors'])\n",
        "                        if first_author_match:\n",
        "                            first_author = first_author_match.group(1).lower()\n",
        "\n",
        "                    year = record.get('year', '')\n",
        "\n",
        "                    bibtex_key = f\"{first_author}_{year}_{record['id']}\"\n",
        "                    bibtex_key = re.sub(r'[^a-z0-9_]', '', bibtex_key)\n",
        "\n",
        "                    f.write(f\"@article{{{bibtex_key},\\n\")\n",
        "\n",
        "                    if record.get('title'):\n",
        "                        title = record['title'].replace(\"{\", \"\\\\{\").replace(\"}\", \"\\\\}\")\n",
        "                        f.write(f\"  title = {{{title}}},\\n\")\n",
        "\n",
        "                    if record.get('authors'):\n",
        "                        authors = record['authors'].replace(\"{\", \"\\\\{\").replace(\"}\", \"\\\\}\")\n",
        "                        f.write(f\"  author = {{{authors}}},\\n\")\n",
        "\n",
        "                    if record.get('year'):\n",
        "                        f.write(f\"  year = {{{record['year']}}},\\n\")\n",
        "\n",
        "                    if record.get('source'):\n",
        "                        journal_match = re.match(r'(.+?)(?:\\s+\\d{4}|$)', record['source'])\n",
        "                        if journal_match:\n",
        "                            journal = journal_match.group(1).strip()\n",
        "                            f.write(f\"  journal = {{{journal}}},\\n\")\n",
        "                        else:\n",
        "                            f.write(f\"  journal = {{{record['source']}}},\\n\")\n",
        "\n",
        "                    if record.get('abstract'):\n",
        "                        abstract = record['abstract'].replace(\"{\", \"\\\\{\").replace(\"}\", \"\\\\}\")\n",
        "                        f.write(f\"  abstract = {{{abstract}}},\\n\")\n",
        "\n",
        "                    if record.get('url'):\n",
        "                        f.write(f\"  url = {{{record['url']}}},\\n\")\n",
        "\n",
        "                    notes = []\n",
        "                    if record.get('method') and record['method'] != 'N/A':\n",
        "                        notes.append(f\"Method: {record['method']}\")\n",
        "                    if record.get('score') and record['score'] != 'N/A':\n",
        "                        notes.append(f\"Score: {record['score']}\")\n",
        "\n",
        "                    if notes:\n",
        "                        note_text = \"; \".join(notes)\n",
        "                        f.write(f\"  note = {{{note_text}}},\\n\")\n",
        "\n",
        "                    f.write(\"}\\n\\n\")\n",
        "\n",
        "            return bibtex_file\n",
        "\n",
        "        except Exception as e:\n",
        "            logging.error(f\"BibTeXへの変換中にエラーが発生しました: {str(e)}\")\n",
        "            return None\n",
        "\n",
        "    def scrape(self):\n",
        "        \"\"\"検索結果をスクレイピングする\"\"\"\n",
        "        try:\n",
        "            logging.info(f\"検索URLからのスクレイピングを開始: {self.search_url}\")\n",
        "\n",
        "            response = self.make_request(self.search_url)\n",
        "            if not response:\n",
        "                return {\"success\": False, \"message\": \"検索結果の取得に失敗しました\"}\n",
        "\n",
        "            if self.debug:\n",
        "                with open(\"debug_page.html\", \"w\", encoding=\"utf-8\") as f:\n",
        "                    f.write(response.text)\n",
        "                logging.debug(\"検索結果ページのHTMLを保存しました: debug_page.html\")\n",
        "\n",
        "            soup = BeautifulSoup(response.text, 'html.parser')\n",
        "\n",
        "            self.total_records = self.get_total_records(soup)\n",
        "            logging.info(f\"検索結果の総レコード数: {self.total_records}\")\n",
        "\n",
        "            if self.total_records == 0:\n",
        "                return {\"success\": False, \"message\": \"検索結果が見つかりませんでした\"}\n",
        "\n",
        "            table_records = self.extract_table_records(soup)\n",
        "            logging.info(f\"検索結果テーブルから {len(table_records)} 件のレコードを抽出しました\")\n",
        "\n",
        "            pagination_links = self.get_pagination_links(soup)\n",
        "            logging.info(f\"ページネーションリンク数: {len(pagination_links)}\")\n",
        "\n",
        "            all_table_records = table_records.copy()\n",
        "\n",
        "            for page_url in pagination_links:\n",
        "                logging.info(f\"追加ページの処理: {page_url}\")\n",
        "\n",
        "                delay = random.uniform(self.delay_min, self.delay_max)\n",
        "                logging.info(f\"{delay:.2f}秒間待機しています...\")\n",
        "                time.sleep(delay)\n",
        "\n",
        "                page_response = self.make_request(page_url)\n",
        "                if not page_response:\n",
        "                    logging.error(f\"ページの取得に失敗しました: {page_url}\")\n",
        "                    continue\n",
        "\n",
        "                page_soup = BeautifulSoup(page_response.text, 'html.parser')\n",
        "\n",
        "                page_records = self.extract_table_records(page_soup)\n",
        "                logging.info(f\"ページから {len(page_records)} 件のレコードを抽出しました\")\n",
        "\n",
        "                all_table_records.extend(page_records)\n",
        "\n",
        "            processed_count = 0\n",
        "\n",
        "            for table_record in all_table_records:\n",
        "                record_id = table_record.get('id')\n",
        "                record_url = table_record.get('url')\n",
        "\n",
        "                if not record_id or not record_url:\n",
        "                    logging.warning(f\"レコードIDまたはURLが不足しています: {table_record}\")\n",
        "                    continue\n",
        "\n",
        "                logging.info(f\"記録を選択しています: ID={record_id}, タイトル={table_record.get('title')}\")\n",
        "\n",
        "                delay = random.uniform(self.delay_min, self.delay_max)\n",
        "                logging.info(f\"{delay:.2f}秒間待機しています...\")\n",
        "                time.sleep(delay)\n",
        "\n",
        "                record_details = self.get_record_details(record_id, record_url)\n",
        "\n",
        "                if record_details:\n",
        "                    logging.info(f\"記録 {record_id} の詳細情報を取得しました: \")\n",
        "                    self.select_record(record_details, table_record)\n",
        "                else:\n",
        "                    logging.warning(f\"記録 {record_id} の詳細情報の取得に失敗しました\")\n",
        "                    basic_record = {\n",
        "                        'id': record_id,\n",
        "                        'title': table_record.get('title', ''),\n",
        "                        'authors': '',\n",
        "                        'year': '',\n",
        "                        'source': '',\n",
        "                        'abstract': '',\n",
        "                        'url': record_url\n",
        "                    }\n",
        "                    self.select_record(basic_record, table_record)\n",
        "\n",
        "                processed_count += 1\n",
        "                self.display_progress(processed_count, len(all_table_records))\n",
        "\n",
        "            print()  # 進捗表示の後に改行\n",
        "\n",
        "            export_result = self.export_selected_records()\n",
        "\n",
        "            if not export_result:\n",
        "                return {\"success\": False, \"message\": \"記録のエクスポートに失敗しました\"}\n",
        "\n",
        "            return {\n",
        "                \"success\": True,\n",
        "                \"total_records\": len(self.selected_records),\n",
        "                \"endnote_file\": export_result[\"endnote_file\"],\n",
        "                \"bib_file\": export_result[\"bib_file\"]\n",
        "            }\n",
        "\n",
        "        except Exception as e:\n",
        "            logging.error(f\"スクレイピング中にエラーが発生しました: {str(e)}\")\n",
        "            return {\"success\": False, \"message\": f\"スクレイピング中にエラーが発生しました: {str(e)}\"}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "6a1e6fc7",
      "metadata": {
        "id": "6a1e6fc7"
      },
      "outputs": [],
      "source": [
        "def build_search_url(keyword):\n",
        "    \"\"\"\n",
        "    キーワードから検索URLを生成する関数\n",
        "\n",
        "    引数:\n",
        "        keyword (str): 検索キーワード\n",
        "\n",
        "    戻り値:\n",
        "        str: 検索URL\n",
        "    \"\"\"\n",
        "    encoded_keyword = urllib.parse.quote_plus(keyword)\n",
        "\n",
        "    base_url = \"https://search.pedro.org.au/advanced-search/results\"\n",
        "    search_url = f\"{base_url}?abstract_with_title={encoded_keyword}&therapy=0&problem=0&body_part=0&subdiscipline=0&topic=0&method=0&authors_association=&title=&source=&year_of_publication=&date_record_was_created=&nscore=&perpage=20&find=&find=Start+Search\"\n",
        "\n",
        "    return search_url\n",
        "\n",
        "def is_valid_pedro_url(url):\n",
        "    \"\"\"\n",
        "    URLがPedroの検索結果URLかどうかを確認する関数\n",
        "\n",
        "    引数:\n",
        "        url (str): 確認するURL\n",
        "\n",
        "    戻り値:\n",
        "        bool: 有効なPedro検索URLならTrue、そうでなければFalse\n",
        "    \"\"\"\n",
        "    if not url.startswith(\"https://search.pedro.org.au/\"):\n",
        "        return False\n",
        "\n",
        "    if \"/advanced-search/results\" not in url and \"/search/results\" not in url:\n",
        "        return False\n",
        "\n",
        "    return True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "152b74f5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 184
        },
        "id": "152b74f5",
        "outputId": "836ffcf3-9857-439f-bdc1-98ba38c540ae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "検索方法を選択してください（1: キーワード検索、2: 高度な検索URL）: 1\n",
            "検索キーワードを入力してください（例: lung cancer）: als lung\n",
            "生成された検索URL: https://search.pedro.org.au/advanced-search/results?abstract_with_title=als+lung&therapy=0&problem=0&body_part=0&subdiscipline=0&topic=0&method=0&authors_association=&title=&source=&year_of_publication=&date_record_was_created=&nscore=&perpage=20&find=&find=Start+Search\n",
            "進捗状況: 8/8 件処理済み (100.0%) - 選択済み: 8 件\n",
            "\n",
            "成功！ 8 件のレコードが取得されました。\n",
            "EndNote ファイル: pedro_export.enw\n",
            "BibTeX ファイル: pedro_export.bib\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_508c79f2-d156-445c-99db-a55b62e38345\", \"pedro_export.bib\", 16891)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_992f0f1b-fa17-4cae-b84a-bca54e833e54\", \"pedro_export.enw\", 16434)"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# 検索方法を選択\n",
        "search_method = input(\"検索方法を選択してください（1: キーワード検索、2: 高度な検索URL）: \")\n",
        "\n",
        "search_url = None\n",
        "\n",
        "if search_method == \"1\":\n",
        "    search_keyword = input(\"検索キーワードを入力してください（例: lung cancer）: \")\n",
        "    search_url = build_search_url(search_keyword)\n",
        "    print(f\"生成された検索URL: {search_url}\")\n",
        "\n",
        "elif search_method == \"2\":\n",
        "    print(\"高度な検索URLを入力してください。\")\n",
        "    print(\"ヒント: https://search.pedro.org.au/advanced-search で検索条件を設定し、検索後のURLをコピーしてください。\")\n",
        "    search_url = input(\"URL: \")\n",
        "\n",
        "    if not is_valid_pedro_url(search_url):\n",
        "        print(\"警告: 入力されたURLはPedroの検索URLではないようです。\")\n",
        "        proceed = input(\"それでも続行しますか？ (y/n): \")\n",
        "        if proceed.lower() != 'y':\n",
        "            raise ValueError(\"無効なURLが入力されました。スクリプトを終了します。\")\n",
        "else:\n",
        "    raise ValueError(\"無効な選択です。1または2を入力してください。\")\n",
        "\n",
        "scraper = PedroScraper(\n",
        "    search_url=search_url,\n",
        "    delay_min=2,\n",
        "    delay_max=4,\n",
        "    debug=False\n",
        ")\n",
        "\n",
        "result = scraper.scrape()\n",
        "\n",
        "if result[\"success\"]:\n",
        "    print(f\"\\n成功！ {result['total_records']} 件のレコードが取得されました。\")\n",
        "    print(f\"EndNote ファイル: {result['endnote_file']}\")\n",
        "    print(f\"BibTeX ファイル: {result['bib_file']}\")\n",
        "\n",
        "    files.download(result[\"bib_file\"])\n",
        "    files.download(result[\"endnote_file\"])\n",
        "\n",
        "else:\n",
        "    print(f\"\\nエラー: {result['message']}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}